{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e85c4314",
   "metadata": {},
   "source": [
    "## Fine-tuning of WizardLM-13B on EdtSum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05511d38",
   "metadata": {},
   "source": [
    "Install and Load Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eff1224a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install -q -U transformers\n",
    "! pip install -q -U datasets\n",
    "! pip3 install -q -U peft\n",
    "! pip install -q -U trl\n",
    "! pip3 install -q -U auto-gptq\n",
    "! pip3 install -q -U optimum\n",
    "! pip3 install -q -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a4e18d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/home/kmb85/rds/hpc-work/huggingface'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5295af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kmb85/rds/hpc-work/miniconda3/lib/python3.11/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    prepare_model_for_kbit_training,\n",
    "    get_peft_model\n",
    ")\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80dbdd3",
   "metadata": {},
   "source": [
    "### Load WizardLM-13B and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fe1a3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kmb85/rds/hpc-work/miniconda3/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/home/kmb85/rds/hpc-work/miniconda3/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/home/kmb85/rds/hpc-work/miniconda3/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/kmb85/rds/hpc-work/miniconda3/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name_or_path = \"WizardLM/WizardLM-13B-V1.2\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4b_quant_type='nf4',\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    use_safetensors=True,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=bnb_config,\n",
    "    token=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08c49ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True,\n",
    "                                          token=\"\")\n",
    "tokenizer.pad_token=tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52d3090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de179967",
   "metadata": {},
   "source": [
    "### Load LoRA Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb938de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=16,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CASUAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"v_proj\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7c0ee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0836942",
   "metadata": {},
   "source": [
    "### Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad71dd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('ChanceFocus/flare-edtsum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30f51ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['id', 'query', 'answer', 'text'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a52a3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "total_size = 2000\n",
    "train_size = int(0.7 * total_size)\n",
    "test_size = int(0.15 * total_size)\n",
    "\n",
    "train_subset = dataset['test'].select(range(train_size))\n",
    "test_subset = dataset['test'].select(range(train_size, train_size + test_size))\n",
    "validation_subset = dataset['test'].select(range(train_size + test_size, total_size))\n",
    "\n",
    "split_datasets = DatasetDict({\n",
    "    'train': train_subset,\n",
    "    'test': test_subset,\n",
    "    'validation': validation_subset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c951253d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"You are given a text that consists of multiple sentences. Your task is to perform abstractive summarization on this text. Use your understanding of the content to express the main ideas and crucial details in a shorter, coherent, and natural sounding text.\"\n",
    "\n",
    "def generate_train_prompt(data_point):\n",
    "    input_text = data_point['text']\n",
    "    summary = data_point['answer']\n",
    "    text = f'{prompt}\\n###Input:\\n{input_text}\\n###Output:\\n{summary}'\n",
    "    return {'text': text, 'labels': summary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c81920f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8815619b47747d6ab83885b96ba4f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = split_datasets['train'].shuffle().map(generate_train_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6050f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ea3a8002b143c8b1fb9f90126fe664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "validation_dataset = split_datasets['validation'].shuffle().map(generate_train_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85a4c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_prompt(data_point):\n",
    "    input_text = data_point['text']\n",
    "    text = f'{prompt}\\n###Input:\\n{input_text}\\n###Output:\\n'\n",
    "    return {'text': text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ce2ba9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96c69c71e6394268b1f0b1542007110d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = split_datasets['test'].shuffle().map(generate_test_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eedfce",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57716562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11339808c5494260b29347a71cff1e67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af8dfe8d7395489c8ccb1d4ca8497de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kmb85/rds/hpc-work/miniconda3/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "training_args = transformers.TrainingArguments(\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=8,\n",
    "    learning_rate=0.00003,\n",
    "    bf16=True,\n",
    "    num_train_epochs=8,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_safetensors=True,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    output_dir='./experiments',\n",
    "    remove_unused_columns=False,\n",
    "    warmup_ratio=0.03,\n",
    "    logging_strategy='steps',\n",
    "    evaluation_strategy='steps',\n",
    "    logging_steps=15,\n",
    "    label_names=['labels'],\n",
    "    eval_steps=15,\n",
    "    group_by_length=True\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    dataset_text_field='text',\n",
    "    peft_config=config,\n",
    "    max_seq_length=4096\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7e99735",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkmb85\u001b[0m (\u001b[33mcam_kiril\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/rds/user/kmb85/hpc-work/R255_Project/wandb/run-20240320_144033-fom9fu0k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cam_kiril/huggingface/runs/fom9fu0k' target=\"_blank\">clear-haze-268</a></strong> to <a href='https://wandb.ai/cam_kiril/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cam_kiril/huggingface' target=\"_blank\">https://wandb.ai/cam_kiril/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cam_kiril/huggingface/runs/fom9fu0k' target=\"_blank\">https://wandb.ai/cam_kiril/huggingface/runs/fom9fu0k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kmb85/rds/hpc-work/miniconda3/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='168' max='168' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [168/168 3:20:40, Epoch 7/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.602600</td>\n",
       "      <td>1.505949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.535700</td>\n",
       "      <td>1.448113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.490700</td>\n",
       "      <td>1.388971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.425000</td>\n",
       "      <td>1.328787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.352200</td>\n",
       "      <td>1.291900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.325700</td>\n",
       "      <td>1.278317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>1.314100</td>\n",
       "      <td>1.269004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.313600</td>\n",
       "      <td>1.263967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>1.315600</td>\n",
       "      <td>1.261327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.296800</td>\n",
       "      <td>1.260275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>1.290600</td>\n",
       "      <td>1.260114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./experiments/checkpoint-21 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/home/kmb85/rds/hpc-work/miniconda3/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory ./experiments/checkpoint-43 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/home/kmb85/rds/hpc-work/miniconda3/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory ./experiments/checkpoint-65 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/home/kmb85/rds/hpc-work/miniconda3/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory ./experiments/checkpoint-87 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/home/kmb85/rds/hpc-work/miniconda3/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory ./experiments/checkpoint-109 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/home/kmb85/rds/hpc-work/miniconda3/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory ./experiments/checkpoint-131 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/home/kmb85/rds/hpc-work/miniconda3/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory ./experiments/checkpoint-153 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/home/kmb85/rds/hpc-work/miniconda3/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory ./experiments/checkpoint-168 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=168, training_loss=1.3867902329989843, metrics={'train_runtime': 12186.1862, 'train_samples_per_second': 0.919, 'train_steps_per_second': 0.014, 'total_flos': 1.0787647261741056e+18, 'train_loss': 1.3867902329989843, 'epoch': 7.68})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.use_cache = False\n",
    "trainer.state.log_history = True\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efc42a7",
   "metadata": {},
   "source": [
    "### Save the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "385105aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(f'WizardLM-13B-edtsum_batch_size_8_epochs_8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1c0316",
   "metadata": {},
   "source": [
    "### Evaluate the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4b2813a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = test_dataset.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5134615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import ast\n",
    "\n",
    "request = {\n",
    "    'max_new_tokens': 200,\n",
    "    'temperature': 0.1,\n",
    "    'repetition_penalty': 1,\n",
    "    'top_p': 0.7,\n",
    "}\n",
    "\n",
    "url = \"http://127.0.0.1:5070/api/v1/generate\"\n",
    "headers = {'Content-Type': 'application/json'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aac0af77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_float_string(s):\n",
    "    s = s.replace('###', '')\n",
    "    s = s.replace('\\n', '')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20a99c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1448471/878058592.py:5: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  rouge_metric = load_metric(\"rouge\")\n",
      "/home/kmb85/rds/hpc-work/miniconda3/lib/python3.11/site-packages/datasets/load.py:752: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.16.1/metrics/rouge/rouge.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "import requests\n",
    "import ast\n",
    "\n",
    "rouge_metric = load_metric(\"rouge\")\n",
    "\n",
    "total_scores = {'rouge1': [], 'rouge2': [], 'rougeL': [], 'rougeLsum': []}\n",
    "num_evaluated = 0\n",
    "\n",
    "for i in range(len(test_dataset)):\n",
    "    request['prompt'] = test_dataset[i]['text']\n",
    "    response = requests.post(url, json=request)\n",
    "\n",
    "    prediction_text = ast.literal_eval(response.text)[\"results\"][0]['text'].lower()\n",
    "    correct_ans_text = trim_float_string(test_dataset[i]['answer'].lower())\n",
    "\n",
    "    if not prediction_text.strip() or not correct_ans_text.strip():\n",
    "        continue\n",
    "\n",
    "    rouge_scores = rouge_metric.compute(predictions=[prediction_text], references=[correct_ans_text])\n",
    "\n",
    "    for key in total_scores.keys():\n",
    "        total_scores[key].append(rouge_scores[key].mid.fmeasure)\n",
    "    num_evaluated += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d7ab43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROUGE Scores fine-tuned model: {'rouge1': 0.20703350009989505, 'rouge2': 0.10989082512507194, 'rougeL': 0.1692579996830393, 'rougeLsum': 0.16966090762580183}\n"
     ]
    }
   ],
   "source": [
    "average_scores = {key: sum(values) / num_evaluated for key, values in total_scores.items() if num_evaluated > 0}\n",
    "print(f\"Average ROUGE Scores fine-tuned model: {average_scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253a6c53",
   "metadata": {},
   "source": [
    "### Evaluate the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dd3207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = test_dataset.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ae2290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import ast\n",
    "\n",
    "request = {\n",
    "    'max_new_tokens': 200,\n",
    "    'temperature': 0.1,\n",
    "    'repetition_penalty': 1,\n",
    "    'top_p': 0.7,\n",
    "}\n",
    "\n",
    "url = \"http://127.0.0.1:5030/api/v1/generate\"\n",
    "headers = {'Content-Type': 'application/json'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5062aecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_float_string(s):\n",
    "    s = s.replace('###', '')\n",
    "    s = s.replace('\\n', '')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97fbcd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_232498/878058592.py:5: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  rouge_metric = load_metric(\"rouge\")\n",
      "/home/kmb85/rds/hpc-work/miniconda3/lib/python3.11/site-packages/datasets/load.py:752: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.16.1/metrics/rouge/rouge.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "import requests\n",
    "import ast\n",
    "\n",
    "rouge_metric = load_metric(\"rouge\")\n",
    "\n",
    "total_scores = {'rouge1': [], 'rouge2': [], 'rougeL': [], 'rougeLsum': []}\n",
    "num_evaluated = 0\n",
    "\n",
    "for i in range(len(test_dataset)):\n",
    "    request['prompt'] = test_dataset[i]['text']\n",
    "    response = requests.post(url, json=request)\n",
    "\n",
    "    prediction_text = ast.literal_eval(response.text)[\"results\"][0]['text'].lower()\n",
    "    correct_ans_text = trim_float_string(test_dataset[i]['answer'].lower())\n",
    "\n",
    "    if not prediction_text.strip() or not correct_ans_text.strip():\n",
    "        continue\n",
    "\n",
    "    rouge_scores = rouge_metric.compute(predictions=[prediction_text], references=[correct_ans_text])\n",
    "\n",
    "    for key in total_scores.keys():\n",
    "        total_scores[key].append(rouge_scores[key].mid.fmeasure)\n",
    "    num_evaluated += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2b68cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROUGE Scores: {'rouge1': 0.18480767445062993, 'rouge2': 0.08276666205900492, 'rougeL': 0.14285202317736728, 'rougeLsum': 0.14491822014612332}\n"
     ]
    }
   ],
   "source": [
    "average_scores = {key: sum(values) / num_evaluated for key, values in total_scores.items() if num_evaluated > 0}\n",
    "print(f\"Average ROUGE Scores: {average_scores}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.11current",
   "language": "python",
   "name": "python3.11current"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
